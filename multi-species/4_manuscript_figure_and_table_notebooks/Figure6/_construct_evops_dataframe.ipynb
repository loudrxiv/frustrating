{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries, define constants, functions, and classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../3_train_and_test_models\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from params import ROOT, SPECIES, TFS\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{ROOT}/plots\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HOLDOUTS    = [None, 0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Helper functions we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds_file(test_species, tf, holdout):\n",
    "    preds_root = ROOT + \"/model_out\"\n",
    "    os.makedirs(preds_root, exist_ok=True)\n",
    "    if holdout is None:\n",
    "        return f\"{preds_root}/EvoPS-None_{tf}_{test_species}-tested.preds.npy\"\n",
    "    else:\n",
    "        return f\"{preds_root}/EvoPS-{holdout}_{tf}_{test_species}-tested.preds.npy\"\n",
    "\n",
    "def get_labels_file(test_species, tf, holdout):\n",
    "    preds_root = ROOT + \"/model_out\"\n",
    "    os.makedirs(preds_root, exist_ok=True)\n",
    "    if holdout is None:\n",
    "        return f\"{preds_root}/EvoPS-None_{tf}_{test_species}-tested.labels.npy\"\n",
    "    else:\n",
    "        return f\"{preds_root}/EvoPS-{holdout}_{tf}_{test_species}-tested.labels.npy\"\n",
    "\n",
    "def load_all_test_sets():\n",
    "    preds_dict  = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
    "    labels_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
    "    for tf in TFS:\n",
    "        for holdout in HOLDOUTS:\n",
    "            print(f\"=== {tf}-Evo with {holdout} holdouts ===\")\n",
    "            preds_file  = get_preds_file(tf=tf, test_species=\"hg38\", holdout=holdout)\n",
    "            labels_file = get_labels_file(tf=tf, test_species=\"hg38\", holdout=holdout)\n",
    "            preds_dict[tf][\"EvoPS\"][holdout]    = np.load(preds_file)\n",
    "            labels_dict[tf][\"EvoPS\"][holdout]   = np.load(labels_file)\n",
    "\n",
    "    return preds_dict, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_seaborn(auPRC_dicts, auROC_dicts):\n",
    "\n",
    "    # This function re-formats the performance dictionaries into\n",
    "    # one pandas DataFrame that matches how seaborn expects.\n",
    "    tf_col      = []\n",
    "    holdout_col = []\n",
    "    auprc_col   = []\n",
    "    auroc_col   = []\n",
    "    for tf in TFS:\n",
    "        for num_holdout in HOLDOUTS:\n",
    "            tf_col.extend([tf])\n",
    "            holdout_col.extend([num_holdout])\n",
    "\n",
    "            # Now grab the five-fold for the current TF and domain\n",
    "            auprc_col.extend([auPRC_dicts[tf][\"Evo\"][num_holdout]])\n",
    "            auroc_col.extend([auROC_dicts[tf][\"Evo\"][num_holdout]])\n",
    "        \n",
    "    return pd.DataFrame({\"TF\":tf_col, \"Holdouts\":holdout_col, \"auPRC\":auprc_col, \"auROC\":auroc_col})\n",
    "\n",
    "def get_auPRCs(labels, preds):\n",
    "    # This function calculates the auPRC for each set of\n",
    "    # predictions passed in. The length of the 2nd axis\n",
    "    # of the predictions array passed in will be the # of\n",
    "    # auPRCs returned as a list. The length of the 1st axis\n",
    "    # of the predictions array should match the length\n",
    "    # of the labels array.\n",
    "    if len(preds) != len(labels):\n",
    "        print(f\"Truncating so that {len(preds)} matches {len(labels)}\")\n",
    "\n",
    "    # (1) Adjust the label length to match the prediction length\n",
    "    len_to_truncate_by = preds.shape[0]\n",
    "\n",
    "    labels = labels[:len_to_truncate_by]\n",
    "\n",
    "    # (3) Calculate the AUC-ROC and AUC-PR for each of the five-folds\n",
    "    return average_precision_score(labels, preds)\n",
    "\n",
    "def get_auROCs(labels, preds):\n",
    "    # This function calculates the auROC for each set of\n",
    "    # predictions passed in. The length of the 2nd axis\n",
    "    # of the predictions array passed in will be the # of\n",
    "    # auROCs returned as a list. The length of the 1st axis\n",
    "    # of the predictions array should match the length\n",
    "    # of the labels array.\n",
    "    if len(preds) != len(labels):\n",
    "        print(f\"Truncating so that {len(preds)} matches {len(labels)}\")\n",
    "\n",
    "    # (1) Adjust the label length to match the prediction length\n",
    "    len_to_truncate_by = preds.shape[0]\n",
    "\n",
    "    labels = labels[:len_to_truncate_by]\n",
    "\n",
    "    # (3) Calculate the AUC-ROC and AUC-PR for each of the five-folds\n",
    "    return roc_auc_score(labels, preds)\n",
    "\n",
    "def get_performance_df(preds_dict, labels_dict):\n",
    "\n",
    "    # This function loads in binding labels for each TF for \n",
    "    # a given test species, and for each TF, calculates the auPRC\n",
    "    # using each set of predictions that is input in \"preds_dict\".\n",
    "    auPRC_dicts = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
    "    auROC_dicts = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(dict))))\n",
    "    for tf in TFS:\n",
    "        for holdout in HOLDOUTS:\n",
    "            model_preds = preds_dict[tf][\"EvoPS\"][holdout].squeeze()\n",
    "            labels      = labels_dict[tf][\"EvoPS\"][holdout].squeeze()\n",
    "            \n",
    "            # Save predictions\n",
    "            auPRC_dicts[tf][\"Evo\"][holdout] = get_auPRCs(labels, model_preds)\n",
    "            auROC_dicts[tf][\"Evo\"][holdout] = get_auROCs(labels, model_preds)\n",
    "\n",
    "    # Before returning all the auPRCs in dictionaries,\n",
    "    # we just need to reformat how they are stored\n",
    "    # because seaborn expects particularly formatted input\n",
    "    return format_data_for_seaborn(auPRC_dicts, auROC_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save into usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CEBPA-Evo with None holdouts ===\n",
      "=== CEBPA-Evo with 0 holdouts ===\n",
      "=== CEBPA-Evo with 1 holdouts ===\n",
      "=== CEBPA-Evo with 2 holdouts ===\n",
      "=== CEBPA-Evo with 3 holdouts ===\n",
      "=== FOXA1-Evo with None holdouts ===\n",
      "=== FOXA1-Evo with 0 holdouts ===\n",
      "=== FOXA1-Evo with 1 holdouts ===\n",
      "=== FOXA1-Evo with 2 holdouts ===\n",
      "=== FOXA1-Evo with 3 holdouts ===\n",
      "=== HNF4A-Evo with None holdouts ===\n",
      "=== HNF4A-Evo with 0 holdouts ===\n",
      "=== HNF4A-Evo with 1 holdouts ===\n",
      "=== HNF4A-Evo with 2 holdouts ===\n",
      "=== HNF4A-Evo with 3 holdouts ===\n",
      "=== HNF6-Evo with None holdouts ===\n",
      "=== HNF6-Evo with 0 holdouts ===\n",
      "=== HNF6-Evo with 1 holdouts ===\n",
      "=== HNF6-Evo with 2 holdouts ===\n",
      "=== HNF6-Evo with 3 holdouts ===\n"
     ]
    }
   ],
   "source": [
    "preds, labels   = load_all_test_sets()\n",
    "performance_df  = get_performance_df(preds_dict=preds, labels_dict=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TF  Holdouts     auPRC     auROC\n",
      "0   CEBPA       NaN  0.323714  0.944821\n",
      "1   CEBPA       0.0  0.280532  0.949191\n",
      "2   CEBPA       1.0  0.296425  0.944035\n",
      "3   CEBPA       2.0  0.286787  0.933585\n",
      "4   CEBPA       3.0  0.293010  0.931777\n",
      "5   FOXA1       NaN  0.272544  0.939887\n",
      "6   FOXA1       0.0  0.244247  0.927519\n",
      "7   FOXA1       1.0  0.253940  0.934536\n",
      "8   FOXA1       2.0  0.254482  0.931436\n",
      "9   FOXA1       3.0  0.266507  0.935768\n",
      "10  HNF4A       NaN  0.337437  0.936759\n",
      "11  HNF4A       0.0  0.301699  0.929484\n",
      "12  HNF4A       1.0  0.319627  0.937013\n",
      "13  HNF4A       2.0  0.321695  0.936053\n",
      "14  HNF4A       3.0  0.311000  0.932483\n",
      "15   HNF6       NaN  0.201287  0.950069\n",
      "16   HNF6       0.0  0.187023  0.944927\n",
      "17   HNF6       1.0  0.171327  0.940918\n",
      "18   HNF6       2.0  0.165250  0.941845\n",
      "19   HNF6       3.0  0.173098  0.929394\n"
     ]
    }
   ],
   "source": [
    "print(performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TF  Holdouts     auPRC     auROC\n",
      "0   CEBPA         0  0.280532  0.949191\n",
      "1   CEBPA         1  0.296425  0.944035\n",
      "2   CEBPA         2  0.286787  0.933585\n",
      "3   CEBPA         3  0.293010  0.931777\n",
      "4   FOXA1         0  0.244247  0.927519\n",
      "5   FOXA1         1  0.253940  0.934536\n",
      "6   FOXA1         2  0.254482  0.931436\n",
      "7   FOXA1         3  0.266507  0.935768\n",
      "8   HNF4A         0  0.301699  0.929484\n",
      "9   HNF4A         1  0.319627  0.937013\n",
      "10  HNF4A         2  0.321695  0.936053\n",
      "11  HNF4A         3  0.311000  0.932483\n",
      "12   HNF6         0  0.187023  0.944927\n",
      "13   HNF6         1  0.171327  0.940918\n",
      "14   HNF6         2  0.165250  0.941845\n",
      "15   HNF6         3  0.173098  0.929394\n"
     ]
    }
   ],
   "source": [
    "print(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.to_csv(ROOT + f\"/plots/evo-per-species_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genomic_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
